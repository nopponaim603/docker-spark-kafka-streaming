{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "import org.apache.spark.streaming.kafka010.KafkaUtils\n",
    "import org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent\n",
    "import org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe\n",
    "\n",
    "import org.apache.kafka.common.serialization.{BytesDeserializer, StringDeserializer, ByteArraySerializer}\n",
    "import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// initialize Spark\n",
    "\n",
    "val spark = SparkSession.builder.appName(\"Spark Streaming\").getOrCreate();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = spark.readStream.format(\"kafka\").\n",
    "option(\"kafka.bootstrap.servers\", \"kafka:9092\").\n",
    "option(\"subscribe\", \"test-topic\").\n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.NoClassDefFoundError",
     "evalue": "Could not initialize class org.apache.spark.sql.kafka010.KafkaSourceProvider$",
     "output_type": "error",
     "traceback": [
      "java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.sql.kafka010.KafkaSourceProvider$",
      "  at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:326)",
      "  at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)",
      "  at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:236)",
      "  at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:117)",
      "  at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:117)",
      "  at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:33)",
      "  at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:219)",
      "  at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:194)",
      "  ... 48 elided"
     ]
    }
   ],
   "source": [
    "// read from Kafka\n",
    "\n",
    "val inputDF = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"kafka:9092\").option(\"subscribe\", \"sample_topic\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
